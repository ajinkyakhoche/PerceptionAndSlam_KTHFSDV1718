# PerceptionAndSlam_KTHFSDV1718
## Background
Welcome to the perception and slam system of the KTH Formula Student Driverless project for the year 2017-18! So, what do we mean by ‘Perception’ and ‘Slam’? Imagine a self-driving race car standing on an endurance track of FSD. The first thing car needs to do is to ‘perceive’ traffic cone landmarks. We use zed stereo camera as our perception sensor. After the cones have been detected, the car needs to plot them on a map and simultaneously needs to find its global position in the map, which is called SLAM (Simultaneous Localization & Mapping). The map information can be used by navigation team for path-planning and actuation. 

When the first ever KTH FSD team assembled in Sep 2017, we were working with a clean slate. We had no idea where to even start. We hope that this repository would serve as a solid base for next batch of FSD enthusiasts!

## Installation
Refer to Installation for a detailed list of dependencies and instructions

## Description 
This section outlines the flow of logic in the system. For a detailed description of every node, follow the links below:
-	Perception
-	Localization
-	Mapping
-	Visualization

